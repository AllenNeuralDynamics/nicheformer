{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a567d761-d5da-46e3-a752-915b7561401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import anndata as ad\n",
    "from typing import Optional, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nicheformer.models import Nicheformer\n",
    "from nicheformer.data import NicheformerDataset\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd1d26-b834-4b6d-9607-c5db7fa660ec",
   "metadata": {},
   "source": [
    "## load nicheformer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2278c40-a929-41f2-a426-8ec32ac29a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=os.path.join(\"weights\",\"nicheformer.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f48413-1087-4ba3-9883-7e0abeeb4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path': '/home/ec2-user/SageMaker/test_data/spatial/preprocessed/Xenium_Preview_Human_Non_diseased_Lung_With_Add_on_FFPE_outs.h5ad', #'path/to/your/data.h5ad',  # Path to your AnnData file\n",
    "    'technology_mean_path': '/home/ec2-user/SageMaker/nicheformer/data/model_means/merfish_mean_script.npy', #'path/to/technology_mean.npy',  # Path to technology mean file\n",
    "    'checkpoint_path': '/weights/nicheformer.ckpt',  # Path to model checkpoint\n",
    "    'output_path': 'test_data_with_embeddings.h5ad',  # Where to save the result, it is a new h5ad\n",
    "    'output_dir': '.',  # Directory for any intermediate outputs\n",
    "    'batch_size': 32,\n",
    "    'max_seq_len': 1500, \n",
    "    'aux_tokens': 30, \n",
    "    'chunk_size': 100, # to prevent OOM\n",
    "    'num_workers': 4,\n",
    "    'precision': 32,\n",
    "    'embedding_layer': -1,  # Which layer to extract embeddings from (-1 for last layer)\n",
    "    'embedding_name': 'embeddings'  # Name suffix for the embedding key in adata.obsm\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08998d8c-99e0-467d-a1f8-9d05e5de3412",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d11a958-0b8b-4e18-87cd-abb2ba136154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ad.read_h5ad('nicheformer/data/model_means/model.h5ad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da413cbc-975a-4eda-9d62-6267268a5d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Load data\n",
    "adata = ad.read_h5ad(config['data_path'])\n",
    "technology_mean = np.load(config['technology_mean_path'])\n",
    "\n",
    "# format data properly with the model\n",
    "adata = ad.concat([model, adata], join='outer', axis=0)\n",
    "# dropping the first observation \n",
    "adata = adata[1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaefd1d8-6c09-4fb8-b488-0922d768dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:191: Found keys that are in the model state dict but not in the checkpoint: ['pos']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "Niche_model = Nicheformer.load_from_checkpoint(model_path, strict=False)\n",
    "Niche_model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Configure trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=4,\n",
    "    default_root_dir=config['output_dir'],\n",
    "    precision=config.get('precision', 32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7187ff-afb5-4c62-9aa9-305b6d5bc393",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(config['data_path'])\n",
    "technology_mean=np.load(config['technology_mean_path'])\n",
    "\n",
    "adata = ad.concat([model, adata], join='outer', axis=0)\n",
    "# # dropping the first observation \n",
    "adata = adata[1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e46ca036-a102-4dde-a573-5d0a0461846b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20310"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(technology_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3c190da-75ca-4c3c-bd45-cb5b57661553",
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_mean=np.load(config['technology_mean_path'])\n",
    "technology_mean=technology_mean.tolist()\n",
    "np.size(technology_mean)\n",
    "arr2=np.array([1.0])\n",
    "result = np.append(technology_mean, arr2)\n",
    "technology_mean=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e829226-022f-4803-9e69-87e8910c2102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        nan,         nan,         nan, ...,         nan,\n",
       "       14.23553126,  1.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "technology_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6caa18af-29a1-4e7e-ab52-7b8df5718e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2959/2959 [16:24<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "dataset = NicheformerDataset(\n",
    "    adata=adata,\n",
    "    technology_mean=technology_mean,\n",
    "    split='train',\n",
    "    max_seq_len=1500,\n",
    "    aux_tokens=config.get('aux_tokens', 30),\n",
    "    chunk_size=config.get('chunk_size', 100)\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    num_workers=config.get('num_workers', 4),\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d580eb2c-57f7-415c-ab30-d22807bc6532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    default_root_dir=config['output_dir'],\n",
    "    precision=config.get('precision', 32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b09ccecb-c875-4fac-83f1-8596b803c009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29589 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29589"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tqdm(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2478b741-2b00-4f64-af56-a9741da3b2d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1153/29589 [05:58<2:27:22,  3.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Get embeddings from the model\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         emb \u001b[38;5;241m=\u001b[39m Niche_model\u001b[38;5;241m.\u001b[39mget_embeddings(\n\u001b[1;32m     13\u001b[0m             batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[1;32m     14\u001b[0m             layer\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_layer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Default to last layer\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         )\n\u001b[0;32m---> 16\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(\u001b[43memb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Concatenate all embeddings\u001b[39;00m\n\u001b[1;32m     20\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Extracting embeddings...\")\n",
    "embeddings = []\n",
    "device = Niche_model.embeddings.weight.device\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "                for k, v in batch.items()}\n",
    "\n",
    "        # Get embeddings from the model\n",
    "        emb = Niche_model.get_embeddings(\n",
    "            batch=batch,\n",
    "            layer=config.get('embedding_layer', -1)  # Default to last layer\n",
    "        )\n",
    "        embeddings.append(emb.cpu().numpy())\n",
    "\n",
    "\n",
    "# Concatenate all embeddings\n",
    "embeddings = np.concatenate(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4dc9a2-2834-459e-a0fe-173ce5d6e21d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
